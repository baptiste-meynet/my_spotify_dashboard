{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63ec4ca6-5e7f-456a-a558-26165377eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total JSON files loaded: 11\n",
      "Rows with invalid or missing country codes: 1\n",
      "\n",
      "Summary of row counts:\n",
      "  Initial:             148263\n",
      "  After media filter:  147258  (−1005)\n",
      "  After dedup:         147137  (−121)\n",
      "  After track/artist:  147137  (−0)\n",
      "  Remaining UTC rows:  1\n",
      "\n",
      "Cleaned data written to: /Users/baptistemeynet/Downloads/Projects/spotify_dashboard/Spotify Extended Streaming History/final_spotify_history.csv\n",
      "Script completed in 17.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import pytz\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "def convert_to_local(ts_utc, country_code):\n",
    "    \"\"\"Convert a UTC‐localized timestamp to the local timezone for a given country code.\"\"\"\n",
    "    try:\n",
    "        tz_name = pytz.country_timezones[country_code][0]\n",
    "    except (KeyError, IndexError):\n",
    "        tz_name = \"UTC\"\n",
    "    return ts_utc.tz_convert(tz_name)\n",
    "\n",
    "def main():\n",
    "    start = time.time()\n",
    "\n",
    "    # 1. Discover files via glob\n",
    "    data_dir = Path(\"/Users/baptistemeynet/Downloads/Projects/spotify_dashboard/Spotify Extended Streaming History\")\n",
    "    json_files = glob.glob(str(data_dir / \"*.json\"))\n",
    "    print(f\"\\nTotal JSON files loaded: {len(json_files)}\")\n",
    "\n",
    "    # 2. Load & concatenate\n",
    "    dfs = []\n",
    "    for fp in json_files:\n",
    "        dfs.append(pd.read_json(fp))\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Initial row count\n",
    "    counts = {}\n",
    "    counts['initial'] = len(df)\n",
    "\n",
    "    # 3. Filter out non-music media (podcasts/audiobooks)\n",
    "    drop_cols = [\n",
    "        \"episode_name\", \"episode_show_name\", \"spotify_episode_uri\",\n",
    "        \"audiobook_title\", \"audiobook_uri\",\n",
    "        \"audiobook_chapter_uri\", \"audiobook_chapter_title\"\n",
    "    ]\n",
    "    before = len(df)\n",
    "    mask_has_media = df[drop_cols].notnull().any(axis=1)\n",
    "    df = df[~mask_has_media]\n",
    "    counts['after_media_filter'] = len(df)\n",
    "\n",
    "    # 4. Drop unneeded columns\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    # 5. Deduplicate\n",
    "    before = len(df)\n",
    "    df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    counts['after_dedup'] = len(df)\n",
    "\n",
    "    # 6. Filter out rows with missing/blank track or artist\n",
    "    before = len(df)\n",
    "    track_blank = df['master_metadata_track_name'].fillna(\"\").eq(\"\")\n",
    "    artist_blank = df['master_metadata_album_artist_name'].fillna(\"\").eq(\"\")\n",
    "    df = df[~(track_blank | artist_blank)]\n",
    "    counts['after_track_artist_filter'] = len(df)\n",
    "\n",
    "    # 7. Timezone conversion\n",
    "    df['ts_utc'] = pd.to_datetime(df['ts'], utc=True, errors='coerce')\n",
    "    invalid_ts = df['ts_utc'].isna().sum()\n",
    "    if invalid_ts > 0:\n",
    "        df = df[df['ts_utc'].notna()]\n",
    "\n",
    "    # Add tz_name column to identify if timezone resolution is successful\n",
    "    df['tz_name'] = df['conn_country'].map(lambda code: pytz.country_timezones.get(code, [\"UTC\"])[0])\n",
    "    df['tz_is_utc'] = df['tz_name'].eq(\"UTC\")\n",
    "\n",
    "    # Log invalid or missing countries\n",
    "    invalid_country_mask = ~df['conn_country'].isin(pytz.country_timezones.keys())\n",
    "    print(f\"Rows with invalid or missing country codes: {invalid_country_mask.sum()}\")\n",
    "\n",
    "    # Convert to local time\n",
    "    df['ts_local'] = df.apply(\n",
    "        lambda row: convert_to_local(row['ts_utc'], row.get('conn_country', '')), axis=1\n",
    "    )\n",
    "    counts['remaining_utc'] = df['tz_is_utc'].sum()\n",
    "\n",
    "    # 8. Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # 9. Summary\n",
    "    print(\"\\nSummary of row counts:\")\n",
    "    print(f\"  Initial:             {counts['initial']}\")\n",
    "    print(f\"  After media filter:  {counts['after_media_filter']}  (−{counts['initial'] - counts['after_media_filter']})\")\n",
    "    print(f\"  After dedup:         {counts['after_dedup']}  (−{counts['after_media_filter'] - counts['after_dedup']})\")\n",
    "    print(f\"  After track/artist:  {counts['after_track_artist_filter']}  (−{counts['after_dedup'] - counts['after_track_artist_filter']})\")\n",
    "    print(f\"  Remaining UTC rows:  {counts['remaining_utc']}\")\n",
    "\n",
    "    # 10. Export to CSV\n",
    "    out_path = data_dir / \"final_spotify_history.csv\"\n",
    "    df.drop(columns=['ts_utc', 'tz_name', 'tz_is_utc'], inplace=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"\\nCleaned data written to: {out_path}\")\n",
    "    print(f\"Script completed in {round(time.time() - start, 2)} seconds.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7fcee-4418-41d3-8e91-22a4b437bbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
